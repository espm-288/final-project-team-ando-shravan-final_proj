{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b0241a-23cd-4480-ba37-463f214f6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import planetary_computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd7b599-88c7-40dc-9489-5def8a4ab045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_gateway\n",
    "\n",
    "# cluster = None\n",
    "gateway = dask_gateway.Gateway()\n",
    "cluster_options = gateway.cluster_options()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae8dc5e-da84-412d-a039-572bb8c0549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters already exist, latching onto the first one\n",
      "<Client: 'tls://10.244.91.67:8786' processes=2 threads=2, memory=32.00 GiB>\n",
      "https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.8a8f5c781960450dbd6265042e2acb2c/status\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_for_existing_clusters():\n",
    "    if len(gateway.list_clusters()) == 0:\n",
    "        return False   \n",
    "    return True\n",
    "\n",
    "#max is 227\n",
    "def setup_dask_cluster(max=227, mem=16):\n",
    "    \n",
    "    cluster_options[\"worker_memory\"] = mem\n",
    "    \n",
    "    if check_for_existing_clusters():\n",
    "        print (\"Clusters already exist, latching onto the first one\")\n",
    "        \n",
    "        clusters = gateway.list_clusters()\n",
    "        cluster = gateway.connect(clusters[0].name)\n",
    "        \n",
    "        client = cluster.get_client()\n",
    "        \n",
    "    else :\n",
    "        cluster = gateway.new_cluster(cluster_options, shutdown_on_close=False)\n",
    "        client = cluster.get_client()\n",
    "        cluster.adapt(minimum=2, maximum=max)\n",
    "    \n",
    "    \n",
    "    print(client)\n",
    "    print(cluster.dashboard_link)\n",
    "\n",
    "    \n",
    "def shutdown_all_clusters():\n",
    "    \n",
    "    clusters = gateway.list_clusters()\n",
    "    if clusters is not None:\n",
    "        for c in clusters:\n",
    "            cluster = gateway.connect(c.name)\n",
    "            cluster.shutdown()\n",
    "            print (cluster)\n",
    "    \n",
    "# This function will be used to 'override' dask.conpute\n",
    "# check if dask clusters are alive, if so, latch onto it\n",
    "# otherwise spawn a new cluster and do .compute on df\n",
    "def compute(ddf):\n",
    "    setup_dask_cluster()\n",
    "    return ddf.compute()\n",
    "\n",
    "def dashboard():\n",
    "    return cluster.dashboard_link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bf136-d764-4300-910d-9f9fb9603ed6",
   "metadata": {},
   "source": [
    "### Can reduce the resolution to any arbitrary grid line\n",
    "\n",
    "This works on pandas or dask frames only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55eba50-6999-4410-a2ba-134b923d47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_resolution_any(ddf, columns, gsize=0.01):\n",
    "                                \n",
    "    # ddf[['decimallatitude','decimallongitude']] = ddf[['decimallatitude','decimallongitude']]\\\n",
    "    # .apply(lambda x: gsize * pd.Series.round(x/gsize, 0), meta={'decimallatitude': 'float64', 'decimallongitude': 'float64'},\\\n",
    "    #        axis=1)\n",
    "    ddf[columns] = ddf[columns].apply(lambda x: gsize * pd.Series.round(x/gsize, 0),axis=1)\n",
    "    return ddf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61459373-6b61-4812-9e59-527fafdb7353",
   "metadata": {},
   "source": [
    "### Make a grid around every point in a geopandas frame\n",
    "\n",
    "Works on geopandas or dask_geopandas frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a924d6c-6777-4a95-9885-1c3efa266569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "import numpy as np\n",
    "\n",
    "def get_square_around_point(point_geom, gsize):\n",
    "    \n",
    "    delta_size = gsize / 2.0\n",
    "    point_coords = np.array(point_geom.coords[0])\n",
    "\n",
    "    c1 = point_coords + [-delta_size,-delta_size]\n",
    "    c2 = point_coords + [-delta_size,+delta_size]\n",
    "    c3 = point_coords + [+delta_size,+delta_size]\n",
    "    c4 = point_coords + [+delta_size,-delta_size]\n",
    "    \n",
    "    square_geom = shapely.geometry.Polygon([c1,c2,c3,c4])\n",
    "    \n",
    "    return square_geom\n",
    "\n",
    "def get_gdf_with_grids(gdf_with_points, gsize=0.01):\n",
    "    gdf_grid = gdf_with_points.copy()\n",
    "    gdf_grid['geometry'] = gdf_with_points.apply(lambda row: get_square_around_point(row['geometry'],gsize)\\\n",
    "                                                 ,axis=1)\n",
    "    return gdf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef7ca3-1f9c-4846-a863-14397c229d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
